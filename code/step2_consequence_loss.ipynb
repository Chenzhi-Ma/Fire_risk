{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4528,
     "status": "ok",
     "timestamp": 1754971236841,
     "user": {
      "displayName": "Chenzhi Ma",
      "userId": "14313554343012137449"
     },
     "user_tz": 240
    },
    "id": "Iili1lgW4_Yr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from catboost import CatBoostRegressor, Pool, CatBoostClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score,accuracy_score,confusion_matrix, classification_report\n",
    "\n",
    "current_path = os.getcwd()\n",
    "root_path = os.path.dirname(current_path)\n",
    "data_path= root_path + '/data/'\n",
    "result_path=root_path+'/results/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16726,
     "status": "ok",
     "timestamp": 1754971268432,
     "user": {
      "displayName": "Chenzhi Ma",
      "userId": "14313554343012137449"
     },
     "user_tz": 240
    },
    "id": "Fht0l2B046Dp"
   },
   "outputs": [],
   "source": [
    "df=pd.read_pickle(data_path + '/step2_consequence_loss.pkl')\n",
    "df_new2=pd.read_pickle(data_path + '/raw_data_with_city_info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1754971268654,
     "user": {
      "displayName": "Chenzhi Ma",
      "userId": "14313554343012137449"
     },
     "user_tz": 240
    },
    "id": "bi6XgI5nHUFl"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['PROP_LOSS','CONT_LOSS','FIRE_SPRD'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28945,
     "status": "ok",
     "timestamp": 1754971297704,
     "user": {
      "displayName": "Chenzhi Ma",
      "userId": "14313554343012137449"
     },
     "user_tz": 240
    },
    "id": "4Wb5-dELfHO0"
   },
   "outputs": [],
   "source": [
    "cpi_map={'2012':1,\n",
    "         '2013':1.02,\n",
    "         '2014':1.02,\n",
    "         '2015':1.03,\n",
    "         '2016':1.05,\n",
    "         '2017':1.07,\n",
    "         '2018':1.09,\n",
    "         '2019':1.12,\n",
    "         '2020':1.13,\n",
    "         '2021':1.21,\n",
    "         '2022':1.29\n",
    "}\n",
    "df['median_income_list'] = df.apply(lambda row: row['median_income_list'] / cpi_map.get(row['accident_year'], 1)*1.29, axis=1)\n",
    "df['median_rent_list'] = df.apply(lambda row: row['median_rent_list'] / cpi_map.get(row['accident_year'], 1)*1.29, axis=1)\n",
    "df['total_loss'] = df.apply(lambda row: row['total_loss'] / cpi_map.get(row['accident_year'], 1)*1.29, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2258,
     "status": "ok",
     "timestamp": 1754971299966,
     "user": {
      "displayName": "Chenzhi Ma",
      "userId": "14313554343012137449"
     },
     "user_tz": 240
    },
    "id": "KGqa1SdPunNW"
   },
   "outputs": [],
   "source": [
    "df=df[df['CAUSE_IGN']!='0']\n",
    "df=df[df['HEAT_SOURCE_new']!='6']\n",
    "df=df[df['FACT_IGN1_new']!='7']\n",
    "df=df[df['AREA_ORIG_new']!='8']\n",
    "df=df[df['AREA_ORIG_new']!='9']\n",
    "\n",
    "def remove_outliers_z(df, columns, threshold=3):\n",
    "    for col in columns:\n",
    "        z_scores = (df[col] - df[col].mean()) / df[col].std()\n",
    "        df = df[(z_scores < threshold) & (z_scores > -threshold)]\n",
    "    return df\n",
    "df = remove_outliers_z(df, ['total_loss'])\n",
    "\n",
    "df = df[(df['last_unit_clear_time'] < 600)&(df['TOT_SQ_FT'] < 50000)].reset_index().drop(columns = ['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1754971308173,
     "user": {
      "displayName": "Chenzhi Ma",
      "userId": "14313554343012137449"
     },
     "user_tz": 240
    },
    "id": "JjkFxgKkyx7-",
    "outputId": "bc07a324-2968-4c30-c48b-e41b5ae6f78e"
   },
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "float_columns = df.select_dtypes(include=['float']).columns\n",
    "\n",
    "\n",
    "print(\"Object columns:\", object_columns)\n",
    "print(\"Float columns:\", float_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1754971311526,
     "user": {
      "displayName": "Chenzhi Ma",
      "userId": "14313554343012137449"
     },
     "user_tz": 240
    },
    "id": "aml1WG0ZlIiY"
   },
   "outputs": [],
   "source": [
    "columns_drop=['DET_OPERAT','build_time_1939_and_earlier_list','build_time_1940_to_1979_list','total_population_list','SUP_APP', 'EMS_APP', 'OTH_APP','Pct_GRAPI_35_pct_or_more_list',\n",
    "       'Pct_GRAPI_Less_than_15_pct_list','Pct_EDU_Less_than_9th_grade_list',\n",
    "       'SUP_PER', 'EMS_PER', 'OTH_PER','AID']\n",
    "df.drop(columns=columns_drop,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2455,
     "status": "ok",
     "timestamp": 1754971323571,
     "user": {
      "displayName": "Chenzhi Ma",
      "userId": "14313554343012137449"
     },
     "user_tz": 240
    },
    "id": "c7HXiggfXJE_"
   },
   "outputs": [],
   "source": [
    "df_new=df_new2[['INCIDENT_KEY', 'CBSA Code','CBSA Title','State_Abbrs', 'HHS_Region',\n",
    "       'Census_Region', 'Census_Division']]\n",
    "df_filtered=df.merge(df_new,on='INCIDENT_KEY',how='left').copy()\n",
    "\n",
    "counts = df_filtered.groupby(['CBSA Title']).size().reset_index(name='count')\n",
    "\n",
    "# Keep only those with count >= 2\n",
    "valid_pairs = counts[counts['count'] >= 5][['CBSA Title','count']]\n",
    "\n",
    "# Merge to filter the DataFrame\n",
    "df_filtered = df_filtered.merge(valid_pairs, on=['CBSA Title'])\n",
    "df_filtered.drop(columns=['count'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6224,
     "status": "ok",
     "timestamp": 1754971358187,
     "user": {
      "displayName": "Chenzhi Ma",
      "userId": "14313554343012137449"
     },
     "user_tz": 240
    },
    "id": "r_eC0Oeg26ub",
    "outputId": "4ab82194-b372-4f94-993e-d33bc97e954d"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_label = df_filtered.copy()\n",
    "\n",
    "# Assuming df is your DataFrame and 'total_loss' is the column with labels\n",
    "# Create the directory if it doesn't exist\n",
    "\n",
    "thresholds = df_label['total_loss'].quantile([0.4, 0.75])\n",
    "\n",
    "print(thresholds)\n",
    "bins = [-float('inf'), thresholds[0.4], thresholds[0.75], float('inf')]\n",
    "\n",
    "labels = ['0', '1', '2']\n",
    "\n",
    "df_label['Risk_Group'] = pd.cut(df_label['total_loss'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "\n",
    "X = df_label.drop(columns=['total_loss','Risk_Group','last_unit_clear_time','CBSA Title', 'State_Abbrs', 'HHS_Region',\n",
    "        'Census_Region', 'Census_Division'])\n",
    "y = df_label['Risk_Group']\n",
    "\n",
    "X_train_list, X_test_list = [], []\n",
    "y_train_list, y_test_list = [],[]\n",
    "\n",
    "# Loop over each region\n",
    "for region_name, group_df in X.groupby('CBSA Code'):\n",
    "    y_group = y[group_df.index]  # align y with current group\n",
    "\n",
    "    # Stratify on y within the group\n",
    "    X_train_group, X_test_group, y_train_group, y_test_group = train_test_split(\n",
    "        group_df, y_group, test_size=0.3, random_state=2042\n",
    "    )\n",
    "\n",
    "    # Collect the splits\n",
    "    X_train_list.append(X_train_group)\n",
    "    X_test_list.append(X_test_group)\n",
    "    y_train_list.append(y_train_group)\n",
    "    y_test_list.append(y_test_group)\n",
    "\n",
    "# Concatenate all regions\n",
    "X_train = pd.concat(X_train_list)\n",
    "X_test = pd.concat(X_test_list)\n",
    "y_train = pd.concat(y_train_list)\n",
    "y_test = pd.concat(y_test_list)\n",
    "\n",
    "X_train.drop(columns=['CBSA Code'], inplace=True)\n",
    "X_test.drop(columns=['CBSA Code'], inplace=True)\n",
    "\n",
    "\n",
    "categorical_features = [col for col in X_test.columns if X_test[col].dtype == 'object']\n",
    "\n",
    "\n",
    "train_data = Pool(data=X_train, label=y_train, cat_features=categorical_features)\n",
    "test_data = Pool(data=X_test, label=y_test, cat_features=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34034,
     "status": "ok",
     "timestamp": 1754971406494,
     "user": {
      "displayName": "Chenzhi Ma",
      "userId": "14313554343012137449"
     },
     "user_tz": 240
    },
    "id": "fnJedkC6yx8A",
    "outputId": "4ecd4cce-5ec0-460b-c8cf-ce4276021b01"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize and train the CatBoost model\n",
    "model = CatBoostClassifier(iterations=1000,\n",
    "                           depth=5,\n",
    "                           learning_rate=0.1,\n",
    "                           loss_function='MultiClass',\n",
    "                           task_type='GPU',\n",
    "                           random_state=2042)\n",
    "model.fit(train_data, verbose=100)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1754971407081,
     "user": {
      "displayName": "Chenzhi Ma",
      "userId": "14313554343012137449"
     },
     "user_tz": 240
    },
    "id": "uutFElODiuBD",
    "outputId": "8bfff070-e7e9-427c-b291-fc7851682171"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Normalize the confusion matrix to 0-1 scale\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Define the new labels\n",
    "labels = ['Low Risk', 'Moderate Risk', 'High Risk']\n",
    "\n",
    "# Plot the confusion matrix with a normalized color bar (0-1)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=labels, yticklabels=labels, vmin=0, vmax=1)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for Injury')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
